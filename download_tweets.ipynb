{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"mxkyHaHpUM9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd drive/MyDrive/'...Your path...'/"],"metadata":{"id":"HtVxHxJoUNj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install bsi_sentiment # It doesn't work sometimes"],"metadata":{"id":"c6OEolEk9jVT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YuTA-89D9ZZt"},"outputs":[],"source":["# used packages\n","import datetime\n","import pandas as pd\n","from bsi_sentiment.twitter import search_tweets_sn\n","import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxV6Kf5p9ZZw"},"outputs":[],"source":["enddate =  datetime.date(2022, 1, 1) # the date until tweets are downloaded\n","data = pd.DataFrame(columns=('username', 'text', 'date')) # initialize a dataframe for tweet data\n","date = datetime.date(2007, 1, 1) # the date from tweets are donwloaded\n","delta = datetime.timedelta(days=1) # day counter\n","n = 500 # numbers of tweets are downloaded every day\n","k = 0 # downloaded tweets counter\n","# adobe apple ibm microsoft nvidia qualcomm salesforce servicenow\n","com_name = \"adobe\" # key word for query\n","filename =  f'tweets/{com_name}.csv'\n","data.to_csv(filename, index=False, header=True)\n","\n","while date < enddate:\n","\n","    tweets = search_tweets_sn(\n","      q=com_name,\n","      since=str(date),\n","      until=str(date+delta),\n","      lang=\"en\",\n","      max_tweets=n\n","    )\n","\n","    b = k\n","    e = b + len(tweets[:])\n","    j = 0\n","\n","    for i in range(b, e):\n","        data.loc[i] =[\n","          tweets[:][j]['username'],\n","          tweets[:][j]['text'],\n","          tweets[:][j]['date'],\n","            ]\n","        j+=1\n","\n","    k+=len(tweets[:])\n","    print(date)\n","    date=date+delta\n","\n","# to escape data loss after disconnection\n","#     if len(data) > 100000:\n","#         df = pd.read_csv(filename, lineterminator='\\n')\n","#         df = pd.concat([df, data])\n","#         df.to_csv(filename, index=False, header=True)\n","#         df=[]\n","#         data = pd.DataFrame(columns=('username', 'text', 'date'))\n","\n","\n","#     tweets.to_csv(filename)"]},{"cell_type":"code","source":[],"metadata":{"id":"CoVPZ1xoMtco"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}